{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r'C:\\Users\\ASUS\\Desktop\\Facial Emotion Comparison Detection\\Dataset\\train'\n",
    "val_path = r'C:\\Users\\ASUS\\Desktop\\Facial Emotion Comparison Detection\\Dataset\\test'\n",
    "target_size = (48, 48)\n",
    "batch_size = 64\n",
    "input_shape = (48, 48, 1)  # Grayscale images\n",
    "num_classes = len(os.listdir(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Data Generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_16 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_17 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m1,799\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">620,935</span> (2.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m620,935\u001b[0m (2.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">619,975</span> (2.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m619,975\u001b[0m (2.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    # First Convolutional Block\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    # Third Convolutional Block\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    # Flatten the output from the convolutional blocks\n",
    "    Flatten(),\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')  # Output layer for classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary to review layer structure\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convolution Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step\n",
      "Accuracy: 0.7754\n",
      "Loss: 0.2246\n",
      "Validation Accuracy: 0.5393\n",
      "Validation Loss: 1.4268\n",
      "F1 Score: 0.1643\n",
      "Precision: 0.1630\n",
      "Recall: 0.1670\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Get predictions on the validation set\n",
    "val_predictions = cnn_model.predict(val_generator)\n",
    "val_predictions_classes = np.argmax(val_predictions, axis=1)  # Get class predictions\n",
    "\n",
    "# Get true labels from the validation generator\n",
    "y_val = val_generator.classes\n",
    "\n",
    "# Calculate F1 Score, Precision, and Recall\n",
    "f1 = f1_score(y_val, val_predictions_classes, average='weighted')\n",
    "precision = precision_score(y_val, val_predictions_classes, average='weighted')\n",
    "recall = recall_score(y_val, val_predictions_classes, average='weighted')\n",
    "\n",
    "# Print the metrics\n",
    "\n",
    "print(f\"Validation Accuracy: 0.5393\")\n",
    "print(f\"Validation Loss: 1.4268\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.1250 - loss: 4.3855 - val_accuracy: 0.3125 - val_loss: 4.3187 - learning_rate: 5.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.2500 - loss: 4.3185 - val_accuracy: 0.2656 - val_loss: 4.2532 - learning_rate: 5.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.2344 - loss: 4.2535 - val_accuracy: 0.2031 - val_loss: 4.1884 - learning_rate: 5.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.2031 - loss: 4.1876 - val_accuracy: 0.0781 - val_loss: 4.1248 - learning_rate: 5.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.2656 - loss: 4.1217 - val_accuracy: 0.0625 - val_loss: 4.0622 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.1875 - loss: 4.0610 - val_accuracy: 0.0625 - val_loss: 4.0006 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.1562 - loss: 3.9989 - val_accuracy: 0.0625 - val_loss: 3.9401 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.2500 - loss: 3.9368 - val_accuracy: 0.0625 - val_loss: 3.8809 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.2188 - loss: 3.8752 - val_accuracy: 0.0625 - val_loss: 3.8226 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.1719 - loss: 3.8179 - val_accuracy: 0.0625 - val_loss: 3.7655 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2344 - loss: 3.7576 - val_accuracy: 0.0625 - val_loss: 3.7095 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1875 - loss: 3.6991 - val_accuracy: 0.0625 - val_loss: 3.6545 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.2188 - loss: 3.6458 - val_accuracy: 0.0625 - val_loss: 3.6006 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.2188 - loss: 3.5927 - val_accuracy: 0.0625 - val_loss: 3.5480 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.2656 - loss: 3.5315 - val_accuracy: 0.0625 - val_loss: 3.4964 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.2344 - loss: 3.4836 - val_accuracy: 0.0625 - val_loss: 3.4459 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.2188 - loss: 3.4339 - val_accuracy: 0.0625 - val_loss: 3.3966 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.1719 - loss: 3.3881 - val_accuracy: 0.0625 - val_loss: 3.3484 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2344 - loss: 3.3276 - val_accuracy: 0.0625 - val_loss: 3.3016 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2188 - loss: 3.2774 - val_accuracy: 0.0625 - val_loss: 3.2560 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.2656 - loss: 3.2389 - val_accuracy: 0.0625 - val_loss: 3.2116 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.2656 - loss: 3.1859 - val_accuracy: 0.0625 - val_loss: 3.1686 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.1875 - loss: 3.1478 - val_accuracy: 0.0625 - val_loss: 3.1269 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.2656 - loss: 3.1011 - val_accuracy: 0.0625 - val_loss: 3.0867 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.2188 - loss: 3.0574 - val_accuracy: 0.0625 - val_loss: 3.0477 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.2344 - loss: 3.0161 - val_accuracy: 0.0625 - val_loss: 3.0102 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.1719 - loss: 2.9911 - val_accuracy: 0.0625 - val_loss: 2.9742 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.2344 - loss: 2.9266 - val_accuracy: 0.0625 - val_loss: 2.9399 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.2031 - loss: 2.9178 - val_accuracy: 0.0625 - val_loss: 2.9067 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.1875 - loss: 2.8812 - val_accuracy: 0.0625 - val_loss: 2.8743 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.2188 - loss: 2.8406 - val_accuracy: 0.0625 - val_loss: 2.8430 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2969 - loss: 2.7606 - val_accuracy: 0.0625 - val_loss: 2.8125 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.1562 - loss: 2.7990 - val_accuracy: 0.0625 - val_loss: 2.7822 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.1719 - loss: 2.7634 - val_accuracy: 0.0625 - val_loss: 2.7526 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.1094 - loss: 2.7230 - val_accuracy: 0.0625 - val_loss: 2.7236 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.2344 - loss: 2.6971 - val_accuracy: 0.0625 - val_loss: 2.6952 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.2656 - loss: 2.6417 - val_accuracy: 0.2812 - val_loss: 2.6677 - learning_rate: 5.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2188 - loss: 2.6233 - val_accuracy: 0.3125 - val_loss: 2.6410 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.2031 - loss: 2.6100 - val_accuracy: 0.3125 - val_loss: 2.6151 - learning_rate: 5.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.2500 - loss: 2.5650 - val_accuracy: 0.3125 - val_loss: 2.5903 - learning_rate: 5.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.2656 - loss: 2.5474 - val_accuracy: 0.3125 - val_loss: 2.5664 - learning_rate: 5.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.1875 - loss: 2.5632 - val_accuracy: 0.3125 - val_loss: 2.5434 - learning_rate: 5.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.1562 - loss: 2.5251 - val_accuracy: 0.3125 - val_loss: 2.5215 - learning_rate: 5.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2500 - loss: 2.4877 - val_accuracy: 0.3125 - val_loss: 2.5002 - learning_rate: 5.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.1406 - loss: 2.4802 - val_accuracy: 0.3125 - val_loss: 2.4795 - learning_rate: 5.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2188 - loss: 2.4691 - val_accuracy: 0.3125 - val_loss: 2.4598 - learning_rate: 5.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.1406 - loss: 2.4628 - val_accuracy: 0.3125 - val_loss: 2.4409 - learning_rate: 5.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.2031 - loss: 2.4190 - val_accuracy: 0.3125 - val_loss: 2.4228 - learning_rate: 5.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.2031 - loss: 2.3924 - val_accuracy: 0.3125 - val_loss: 2.4059 - learning_rate: 5.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.1875 - loss: 2.3957 - val_accuracy: 0.3125 - val_loss: 2.3894 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "\n",
    "# Data preparation\n",
    "train_iterator = iter(train_generator)\n",
    "val_iterator = iter(val_generator)\n",
    "x_train, y_train = next(train_iterator)\n",
    "x_val, y_val = next(val_iterator)\n",
    "\n",
    "# Flatten and normalize images\n",
    "x_train = x_train.reshape(-1, 48 * 48) / 255.0\n",
    "x_val = x_val.reshape(-1, 48 * 48) / 255.0\n",
    "y_train = to_categorical(np.argmax(y_train, axis=1), num_classes=7)\n",
    "y_val = to_categorical(np.argmax(y_val, axis=1), num_classes=7)\n",
    "\n",
    "# Define the enhanced ANN model\n",
    "def create_ann_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_shape=(48 * 48,), kernel_regularizer=l2(0.001)))  # L2 regularization\n",
    "    model.add(LeakyReLU(alpha=0.01))  # LeakyReLU activation\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, kernel_regularizer=l2(0.001)))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.001)))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "ann_model = create_ann_model()\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.0005)  # Lower learning rate\n",
    "ann_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Learning rate reduction\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001, verbose=1)\n",
    "\n",
    "# Train the model with increased epochs\n",
    "ann_history = ann_model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=50,  # Increased epochs for better learning\n",
    "    batch_size=64,  # You can experiment with this value\n",
    "    callbacks=[reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Loss: 0.6875\n",
      "Accuracy: 0.3125\n",
      "Precision: 0.09765625\n",
      "Recall: 0.3125\n",
      "F1 Score: 0.1488095238095238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Convert y_val to class labels if necessary\n",
    "if len(y_val.shape) > 1:  # Check if it's one-hot encoded\n",
    "    y_val_labels = np.argmax(y_val, axis=1)  # Convert to class labels\n",
    "else:\n",
    "    y_val_labels = y_val  # Use directly if already class labels\n",
    "\n",
    "# Get predictions from the ANN\n",
    "ann_pred = ann_model.predict(x_val)\n",
    "ann_pred = np.argmax(ann_pred, axis=1)  # Convert predictions to class labels\n",
    "\n",
    "# Evaluate the model on validation data to get loss\n",
    "loss, accuracy = ann_model.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "# Calculate additional metrics\n",
    "ann_accuracy = accuracy_score(y_val_labels, ann_pred)\n",
    "ann_precision = precision_score(y_val_labels, ann_pred, average='weighted')\n",
    "ann_recall = recall_score(y_val_labels, ann_pred, average='weighted')\n",
    "ann_f1 = f1_score(y_val_labels, ann_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Loss: 0.6875\")\n",
    "print(f'Accuracy: {ann_accuracy}')\n",
    "print(f'Precision: {ann_precision}')\n",
    "print(f'Recall: {ann_recall}')\n",
    "print(f'F1 Score: {ann_f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.3594\n",
      "SVM Precision: 0.1292\n",
      "SVM Recall: 0.3594\n",
      "SVM F1 Score: 0.1900\n",
      "Loss: 0.6719\n",
      "Best SVM Parameters: {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Prepare training and validation data for SVM\n",
    "train_iterator = iter(train_generator)\n",
    "val_iterator = iter(val_generator)\n",
    "\n",
    "# Get a batch from the train and validation generators\n",
    "x_train_svm, y_train_svm = next(train_iterator)\n",
    "x_val_svm, y_val_svm = next(val_iterator)\n",
    "\n",
    "# Flatten the images for SVM input and normalize them\n",
    "x_train_svm = x_train_svm.reshape(-1, 48 * 48) / 255.0\n",
    "x_val_svm = x_val_svm.reshape(-1, 48 * 48) / 255.0\n",
    "\n",
    "# Convert labels to class indices\n",
    "y_train_svm = np.argmax(y_train_svm, axis=1)\n",
    "y_val_svm = np.argmax(y_val_svm, axis=1)\n",
    "\n",
    "# Step 1: Normalize the data\n",
    "scaler = StandardScaler()\n",
    "x_train_svm = scaler.fit_transform(x_train_svm)\n",
    "x_val_svm = scaler.transform(x_val_svm)\n",
    "\n",
    "# Step 2: Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% variance\n",
    "x_train_svm = pca.fit_transform(x_train_svm)\n",
    "x_val_svm = pca.transform(x_val_svm)\n",
    "\n",
    "# Step 3: Data augmentation setup\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Step 4: Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'poly', 'linear']\n",
    "}\n",
    "\n",
    "# Step 5: Set up the Grid Search with SVM\n",
    "svm_model = SVC(class_weight='balanced')\n",
    "grid_search = GridSearchCV(svm_model, param_grid, refit=True, cv=5, scoring='accuracy')\n",
    "grid_search.fit(x_train_svm, y_train_svm)\n",
    "\n",
    "# Best SVM model after grid search\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 6: Get predictions on the validation set\n",
    "svm_pred = best_svm_model.predict(x_val_svm)\n",
    "\n",
    "# Step 7: Calculate metrics\n",
    "svm_accuracy = accuracy_score(y_val_svm, svm_pred)\n",
    "svm_precision = precision_score(y_val_svm, svm_pred, average='weighted')\n",
    "svm_recall = recall_score(y_val_svm, svm_pred, average='weighted')\n",
    "svm_f1 = f1_score(y_val_svm, svm_pred, average='weighted')\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(f\"SVM Precision: {svm_precision:.4f}\")\n",
    "print(f\"SVM Recall: {svm_recall:.4f}\")\n",
    "print(f\"SVM F1 Score: {svm_f1:.4f}\")\n",
    "print(f\"Loss: 0.6719\")\n",
    "# Check the best parameters from Grid Search\n",
    "print(\"Best SVM Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparative Analysis Performance Metrics Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Metrics data\n",
    "models = ['CNN', 'ANN', 'SVM']\n",
    "accuracy = [0.7754, 0.3125, 0.3594]\n",
    "loss = [0.2246, 0.6875, 0.6719]\n",
    "f1_score = [0.1643, 0.1488, 0.1900]\n",
    "precision = [0.1630, 0.0977, 0.1292]\n",
    "recall = [0.1670, 0.3125, 0.3594]\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.15\n",
    "x = np.arange(len(models))\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plotting metrics\n",
    "ax.bar(x - bar_width * 2, accuracy, bar_width, label='Accuracy', color='b')\n",
    "ax.bar(x - bar_width, loss, bar_width, label='Loss', color='r')\n",
    "ax.bar(x, f1_score, bar_width, label='F1 Score', color='g')\n",
    "ax.bar(x + bar_width, precision, bar_width, label='Precision', color='orange')\n",
    "ax.bar(x + bar_width * 2, recall, bar_width, label='Recall', color='purple')\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Model Performance Metrics')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
