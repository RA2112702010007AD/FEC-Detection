{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SE Block\n",
    "def se_block(input_tensor, reduction_ratio=16):\n",
    "    channels = input_tensor.shape[-1]\n",
    "    se_shape = (1, 1, channels)\n",
    "\n",
    "    squeeze = layers.GlobalAveragePooling2D()(input_tensor)\n",
    "    excitation = layers.Dense(channels // reduction_ratio, activation='relu')(squeeze)\n",
    "    excitation = layers.Dense(channels, activation='sigmoid')(excitation)\n",
    "    excitation = layers.Reshape(se_shape)(excitation)\n",
    "\n",
    "    return layers.multiply([input_tensor, excitation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset from CSV\n",
    "def load_dataset(file_path):\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    images = data.iloc[:, ::5].values  # Image URLs\n",
    "    bboxes = data.iloc[:, 1:4].values.reshape(-1, 3, 4)  # Bounding boxes\n",
    "    labels = data.iloc[:, 15:].values.reshape(-1, 3)  # Labels\n",
    "    return images, bboxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and preprocess images\n",
    "def preprocess_data(image_urls, bboxes, labels, img_size=(224, 224)):\n",
    "    processed_images = []\n",
    "    processed_labels = []\n",
    "    for img_set, bbox_set, label_set in zip(image_urls, bboxes, labels):\n",
    "        for img_url, bbox, label in zip(img_set, bbox_set, label_set):\n",
    "            try:\n",
    "                # Download image\n",
    "                resp = requests.get(img_url, stream=True)\n",
    "                img_arr = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
    "                img = cv2.imdecode(img_arr, cv2.IMREAD_COLOR)\n",
    "\n",
    "                # Crop bounding box\n",
    "                h, w, _ = img.shape\n",
    "                x_min, x_max = int(bbox[0] * w), int(bbox[1] * w)\n",
    "                y_min, y_max = int(bbox[2] * h), int(bbox[3] * h)\n",
    "                cropped_img = img[y_min:y_max, x_min:x_max]\n",
    "\n",
    "                # Resize and normalize\n",
    "                resized_img = cv2.resize(cropped_img, img_size) / 255.0\n",
    "                processed_images.append(resized_img)\n",
    "                processed_labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_url}: {e}\")\n",
    "\n",
    "    return np.array(processed_images), np.array(processed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model with SE Blocks\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = se_block(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = se_block(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check file existence\n",
    "train_csv_path = \"C:\\\\Users\\\\ASUS\\\\Desktop\\\\Facial Emotion Comparison Detection\\\\faceexp-comparison-data-train-public.csv\"\n",
    "test_csv_path = \"C:\\\\Users\\\\ASUS\\\\Desktop\\\\Facial Emotion Comparison Detection\\\\faceexp-comparison-data-test-public.csv\"\n",
    "\n",
    "if not os.path.exists(train_csv_path):\n",
    "    print(f\"Train file not found: {train_csv_path}\")\n",
    "if not os.path.exists(test_csv_path):\n",
    "    print(f\"Test file not found: {test_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path):\n",
    "    try:\n",
    "        # Load CSV\n",
    "        data = pd.read_csv(file_path, header=None, engine='python', on_bad_lines='skip')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "    print(f\"Dataset shape: {data.shape}\")\n",
    "\n",
    "    # Extract image URLs\n",
    "    images = data.iloc[:, ::5].values  # Assuming URLs are in every 5th column\n",
    "\n",
    "    # Extract bounding boxes\n",
    "    try:\n",
    "        bboxes = data.iloc[:, 1:13].values.reshape(-1, 3, 4)  # Adjust indices if needed\n",
    "        print(f\"BBoxes shape after reshaping: {bboxes.shape}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error reshaping bounding boxes: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Extract labels\n",
    "    labels = data.iloc[:, 15:].values\n",
    "    print(f\"Labels shape before reshaping: {labels.shape}\")\n",
    "    try:\n",
    "        num_samples = labels.shape[0] // 3\n",
    "        labels = labels.reshape(num_samples, 3)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error reshaping labels: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "    return images, bboxes, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (446536, 28)\n",
      "BBoxes shape after reshaping: (446536, 3, 4)\n",
      "Labels shape before reshaping: (446536, 13)\n",
      "Error reshaping labels: cannot reshape array of size 5804968 into shape (148845,3)\n",
      "Dataset shape: (50845, 28)\n",
      "BBoxes shape after reshaping: (50845, 3, 4)\n",
      "Labels shape before reshaping: (50845, 13)\n",
      "Error reshaping labels: cannot reshape array of size 660985 into shape (16948,3)\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "train_images, train_bboxes, train_labels = load_dataset(train_csv_path)\n",
    "test_images, test_bboxes, test_labels = load_dataset(test_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Preprocess data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_bboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m preprocess_data(test_images, test_bboxes, test_labels)\n",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(image_urls, bboxes, labels, img_size)\u001b[0m\n\u001b[0;32m      3\u001b[0m processed_images \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m processed_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_set, bbox_set, label_set \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_urls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m img_url, bbox, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(img_set, bbox_set, label_set):\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m             \u001b[38;5;66;03m# Download image\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    " # Preprocess data\n",
    "X_train, y_train = preprocess_data(train_images, train_bboxes, train_labels)\n",
    "X_test, y_test = preprocess_data(test_images, test_bboxes, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
